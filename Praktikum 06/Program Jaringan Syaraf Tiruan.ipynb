{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    # Menginisialisasi Perceptron dengan ukuran input, learning rate, dan jumlah epochs\n",
    "    def __init__(self, input_size, lr=1, epochs=100):\n",
    "        self.W = np.zeros(\n",
    "            input_size + 1\n",
    "        )  # Inisialisasi bobot dengan nol, termasuk bias\n",
    "        self.lr = lr  # Learning rate\n",
    "        self.epochs = epochs  # Jumlah epochs (iterasi pelatihan)\n",
    "\n",
    "    # Fungsi aktivasi step function\n",
    "    def activation_fn(self, x):\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "    # Fungsi prediksi untuk menghitung output\n",
    "    def predict(self, x):\n",
    "        z = self.W.T.dot(x)  # Menghitung nilai z (input terintegrasi)\n",
    "        a = self.activation_fn(z)  # Menghitung output menggunakan fungsi aktivasi\n",
    "        return a\n",
    "\n",
    "    # Fungsi untuk melatih model Perceptron\n",
    "    def fit(self, X, d):\n",
    "        for _ in range(self.epochs):  # Looping untuk setiap epoch\n",
    "            for i in range(d.shape[0]):  # Looping untuk setiap sampel dalam dataset\n",
    "                x = np.insert(X[i], 0, 1)  # Menambahkan bias ke input\n",
    "                y = self.predict(x)  # Melakukan prediksi\n",
    "                e = d[i] - y  # Menghitung error\n",
    "                self.W = self.W + self.lr * e * x  # Memperbarui bobot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerbang Logika AND (AND Gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND Gate\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 0\n",
      "[1 1] -> 1\n"
     ]
    }
   ],
   "source": [
    "print(\"AND Gate\")\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Input untuk gerbang AND\n",
    "d = np.array([0, 0, 0, 1])  # Target output untuk gerbang AND\n",
    "and_perceptron = Perceptron(input_size=2)  # Membuat objek Perceptron untuk gerbang AND\n",
    "and_perceptron.fit(X, d)  # Melatih Perceptron dengan data AND\n",
    "for x in X:\n",
    "    print(\n",
    "        f\"{x} -> {and_perceptron.predict(np.insert(x, 0, 1))}\"\n",
    "    )  # Menampilkan hasil prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerbang Logika OR (OR Gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR Gate\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n"
     ]
    }
   ],
   "source": [
    "print(\"OR Gate\")\n",
    "d = np.array([0, 1, 1, 1])  # Target output untuk gerbang OR\n",
    "or_perceptron = Perceptron(input_size=2)  # Membuat objek Perceptron untuk gerbang OR\n",
    "or_perceptron.fit(X, d)  # Melatih Perceptron dengan data OR\n",
    "for x in X:\n",
    "    print(\n",
    "        f\"{x} -> {or_perceptron.predict(np.insert(x, 0, 1))}\"\n",
    "    )  # Menampilkan hasil prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerbang Logika XOR (XOR Gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron:\n",
    "    # Menginisialisasi MLP dengan ukuran input, hidden layer, output, learning rate, dan epochs\n",
    "    def __init__(self, input_size, hidden_size, output_size, lr=1, epochs=10000):\n",
    "        self.V = np.random.randn(\n",
    "            input_size + 1, hidden_size\n",
    "        )  # Inisialisasi bobot input ke hidden layer\n",
    "        self.W = np.random.randn(\n",
    "            hidden_size + 1, output_size\n",
    "        )  # Inisialisasi bobot hidden layer ke output\n",
    "        self.lr = lr  # Learning rate\n",
    "        self.epochs = epochs  # Jumlah epochs (iterasi pelatihan)\n",
    "\n",
    "    # Fungsi aktivasi sigmoid\n",
    "    def activation_fn(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Turunan fungsi aktivasi sigmoid\n",
    "    def activation_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    # Fungsi prediksi untuk MLP\n",
    "    def predict(self, x):\n",
    "        x = np.insert(x, 0, 1)  # Menambahkan bias ke input\n",
    "        self.Z = self.activation_fn(\n",
    "            self.V.T.dot(x)\n",
    "        )  # Menghitung output dari hidden layer\n",
    "        self.Z = np.insert(self.Z, 0, 1)  # Menambahkan bias ke output hidden layer\n",
    "        self.Y = self.activation_fn(self.W.T.dot(self.Z))  # Menghitung output akhir\n",
    "        return self.Y\n",
    "\n",
    "    # Fungsi untuk melatih model MLP\n",
    "    def fit(self, X, d):\n",
    "        for _ in range(self.epochs):  # Looping untuk setiap epoch\n",
    "            for i in range(d.shape[0]):  # Looping untuk setiap sampel dalam dataset\n",
    "                x = np.insert(X[i], 0, 1)  # Menambahkan bias ke input\n",
    "                self.Z = self.activation_fn(\n",
    "                    self.V.T.dot(x)\n",
    "                )  # Menghitung output dari hidden layer\n",
    "                self.Z = np.insert(\n",
    "                    self.Z, 0, 1\n",
    "                )  # Menambahkan bias ke output hidden layer\n",
    "                self.Y = self.activation_fn(\n",
    "                    self.W.T.dot(self.Z)\n",
    "                )  # Menghitung output akhir\n",
    "\n",
    "                e = d[i] - self.Y  # Menghitung error\n",
    "                dW = (\n",
    "                    self.lr * e * self.activation_derivative(self.Y) * self.Z\n",
    "                )  # Memperbarui bobot untuk hidden ke output\n",
    "                dV = (\n",
    "                    self.lr\n",
    "                    * self.activation_derivative(self.Z[1:])\n",
    "                    * x[:, np.newaxis].dot(\n",
    "                        (self.W[1:, 0] * e * self.activation_derivative(self.Y))[\n",
    "                            np.newaxis, :\n",
    "                        ]\n",
    "                    )\n",
    "                )  # Memperbarui bobot untuk input ke hidden\n",
    "\n",
    "                self.W += dW[:, np.newaxis]  # Mengupdate bobot hidden ke output\n",
    "                self.V += dV  # Mengupdate bobot input ke hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR Gate\n",
      "[0 0] -> [0.]\n",
      "[0 1] -> [1.]\n",
      "[1 0] -> [1.]\n",
      "[1 1] -> [0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"XOR Gate\")\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Input untuk gerbang XOR\n",
    "d = np.array([0, 1, 1, 0])  # Target output untuk gerbang XOR\n",
    "xor_mlp = MultiLayerPerceptron(\n",
    "    input_size=2, hidden_size=2, output_size=1\n",
    ")  # Membuat objek MLP untuk gerbang XOR\n",
    "xor_mlp.fit(X, d)  # Melatih MLP dengan data XOR\n",
    "for x in X:\n",
    "    print(f\"{x} -> {xor_mlp.predict(x).round()}\")  # Menampilkan hasil prediksi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
